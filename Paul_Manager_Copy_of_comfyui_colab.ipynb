{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDuke1974/TheDuke1974/blob/main/Paul_Manager_Copy_of_comfyui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "outputId": "290f8a7c-314a-4715-dc3e-f1dce10f0749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-= Initial setup ComfyUI =-\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 16369, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 16369 (delta 14), reused 12 (delta 11), pack-reused 16345 (from 3)\u001b[K\n",
            "Receiving objects: 100% (16369/16369), 52.99 MiB | 9.62 MiB/s, done.\n",
            "Resolving deltas: 100% (10920/10920), done.\n",
            "/content/ComfyUI\n",
            "-= Updating ComfyUI =-\n",
            "Already up to date.\n",
            "-= Install dependencies =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Collecting xformers!=0.0.18\n",
            "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Collecting torchsde (from -r requirements.txt (line 2))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.47.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.11.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (5.9.5)\n",
            "Collecting kornia>=0.7.1 (from -r requirements.txt (line 18))\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting spandrel (from -r requirements.txt (line 19))\n",
            "  Downloading spandrel-0.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers!=0.0.18) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 10)) (1.18.3)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia>=0.7.1->-r requirements.txt (line 18))\n",
            "  Downloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements.txt (line 20)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 20)) (2.22)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.12.14)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spandrel-0.4.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, kornia-rs, xformers, torchsde, kornia, spandrel\n",
            "Successfully installed kornia-0.7.4 kornia-rs-0.1.8 spandrel-0.4.0 torchsde-0.2.6 trampoline-0.1.2 xformers-0.0.29.post1\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = False  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "G-DRIVE ONLY WHEN MAIN CHECK ISN'T TICKED"
      ],
      "metadata": {
        "id": "tU0RF1xdKCLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive #Use this string only if you don't check ✅ at the 1st command \"use google drive\"\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H37sDbeuGxZ8",
        "outputId": "98798c71-9953-449f-d5e2-66dc1ce854e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SD3-Controlnet-Inpainting"
      ],
      "metadata": {
        "id": "USvkFm2S23nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall diffusers\n",
        "pip install git+https://github.com/huggingface/diffusers\n"
      ],
      "metadata": {
        "id": "uza2ypp12rm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SD3-Controlnet-Inpainting"
      ],
      "metadata": {
        "id": "XkAK9VHX26kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers.utils import load_image, check_min_version\n",
        "from diffusers.pipelines import StableDiffusion3ControlNetInpaintingPipeline\n",
        "from diffusers.models.controlnet_sd3 import SD3ControlNetModel\n",
        "\n",
        "controlnet = SD3ControlNetModel.from_pretrained(\n",
        "    \"alimama-creative/SD3-Controlnet-Inpainting\", use_safetensors=True, extra_conditioning_channels=1\n",
        ")\n",
        "pipe = StableDiffusion3ControlNetInpaintingPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.text_encoder.to(torch.float16)\n",
        "pipe.controlnet.to(torch.float16)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "image = load_image(\n",
        "    \"https://huggingface.co/alimama-creative/SD3-Controlnet-Inpainting/resolve/main/images/dog.png\"\n",
        ")\n",
        "mask = load_image(\n",
        "    \"https://huggingface.co/alimama-creative/SD3-Controlnet-Inpainting/resolve/main/images/dog_mask.png\"\n",
        ")\n",
        "width = 1024\n",
        "height = 1024\n",
        "prompt = \"A cat is sitting next to a puppy.\"\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(24)\n",
        "res_image = pipe(\n",
        "    negative_prompt=\"deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, mutated hands and fingers, disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, NSFW\",\n",
        "    prompt=prompt,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    control_image=image,\n",
        "    control_mask=mask,\n",
        "    num_inference_steps=28,\n",
        "    generator=generator,\n",
        "    controlnet_conditioning_scale=0.95,\n",
        "    guidance_scale=7,\n",
        ").images[0]\n",
        "res_image.save(f\"sd3.png\")\n"
      ],
      "metadata": {
        "id": "4_pOJ9JS2uy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPLOAD LORA ❤✅😃▶"
      ],
      "metadata": {
        "id": "Q3TU6nD9WMkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded file to the desired directory\n",
        "for filename, file_content in uploaded.items():\n",
        "  with open(os.path.join('/content/ComfyUI/models/loras', filename), 'wb') as f:\n",
        "    f.write(file_content)\n",
        "\n",
        "print(f\"File '{filename}' saved to '/content/ComfyUI/models/loras/'\")"
      ],
      "metadata": {
        "id": "e5gGTfh4VdlX",
        "outputId": "663b7e2f-ecbd-44ab-90b7-c3e3ca5a8c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edfa5c45-87ef-45a4-af11-bd9e2f53c6ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edfa5c45-87ef-45a4-af11-bd9e2f53c6ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filename' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d088f48dc213>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File '{filename}' saved to '/content/ComfyUI/models/loras/'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ComfyUI-Crystools"
      ],
      "metadata": {
        "id": "zMLynEkUlUVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PythonGosssss - Node colours - TO BE ADJUSTED!!!!!"
      ],
      "metadata": {
        "id": "y_Rje4A-9jWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts #ComfyUI-Custom-Scripts Option 1"
      ],
      "metadata": {
        "id": "mAqXBxX-kypt",
        "outputId": "9c5caae9-8912-41bb-a17f-f1ec296005c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ComfyUI-Custom-Scripts'...\n",
            "remote: Enumerating objects: 2185, done.\u001b[K\n",
            "remote: Counting objects: 100% (538/538), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 2185 (delta 449), reused 413 (delta 394), pack-reused 1647 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2185/2185), 574.95 KiB | 16.91 MiB/s, done.\n",
            "Resolving deltas: 100% (1263/1263), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git /content/gdrive/MyDrive/ComfyUI-Custom-Scripts\n"
      ],
      "metadata": {
        "id": "bBQxklXg5dEY",
        "outputId": "66741dcf-8ad1-411d-d2db-fcc1dbf12494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/gdrive/MyDrive/ComfyUI-Custom-Scripts'...\n",
            "remote: Enumerating objects: 2121, done.\u001b[K\n",
            "remote: Counting objects: 100% (474/474), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 2121 (delta 410), reused 371 (delta 370), pack-reused 1647 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2121/2121), 567.66 KiB | 1.89 MiB/s, done.\n",
            "Resolving deltas: 100% (1225/1225), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ComfyUI-Crystools"
      ],
      "metadata": {
        "id": "B6YQz2p8g_NK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Upload any file"
      ],
      "metadata": {
        "id": "0gFYtXex4gzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "m3vXLSjZ4XkJ",
        "outputId": "117ae7b9-0cb2-41f5-ed6c-9c7998fadde8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf4d7db6-eb7d-480a-870d-5af73e8faee9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf4d7db6-eb7d-480a-870d-5af73e8faee9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-21dc3c638f66>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint from Google Drive to the ComfyUI"
      ],
      "metadata": {
        "id": "8qYoQ9d1KqkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_path = '/content/gdrive/MyDrive/museumExhibitionV10_exhibitionHallV10.safetensors'\n",
        "destination_path = '/content/ComfyUI/models/checkpoints/'\n",
        "\n",
        "shutil.copy(source_path, destination_path)\n",
        "print(f'Copied checkpoint to {destination_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pytSI8YWKlFr",
        "outputId": "5356fdd7-621b-4abf-8abb-81ad23340ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied checkpoint to /content/ComfyUI/models/checkpoints/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ComfyUi - pack - Comfy-Pack: Making ComfyUI Workflows Shareable"
      ],
      "metadata": {
        "id": "xId8_hh7Fqkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!comfy-pack unpack workflow.cpack.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFUnHb6T6lOS",
        "outputId": "67e3d2c2-0b9d-46c1-d79f-9615c77bebbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: comfy-pack: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "rgthree's ComfyUI Nodes ( Download via ComfyUi Manager: ❤👍"
      ],
      "metadata": {
        "id": "cSY7b-pPbjQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ComfyUI/custom_nodes && git clone https://github.com/rgthree/rgthree-comfy.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE7zdazY4_NB",
        "outputId": "23621433-40ab-4030-e5d6-68bd26683311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: ComfyUI/custom_nodes: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRIPTAPE"
      ],
      "metadata": {
        "id": "sq0C5t5lnBje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /path/to/comfyUI\n",
        "cd custom_nodes\n",
        "git clone https://github.com/griptape-ai/ComfyUI-Griptape"
      ],
      "metadata": {
        "id": "FQWs4TsqnAkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GEMINI API KEY"
      ],
      "metadata": {
        "id": "rBu8HbkfmwMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('secretName')"
      ],
      "metadata": {
        "id": "-kJmTX1hmuMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GIT to download Manager"
      ],
      "metadata": {
        "id": "MUclQFS2KA8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager custom_nodes/ComfyUI-Manager"
      ],
      "metadata": {
        "id": "xWAqg4hrLmtW",
        "outputId": "825252f7-67df-4d21-e7fb-30d7a9903901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'custom_nodes/ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 16523, done.\u001b[K\n",
            "remote: Counting objects: 100% (701/701), done.\u001b[K\n",
            "remote: Compressing objects: 100% (323/323), done.\u001b[K\n",
            "remote: Total 16523 (delta 499), reused 379 (delta 378), pack-reused 15822 (from 6)\u001b[K\n",
            "Receiving objects: 100% (16523/16523), 21.63 MiB | 15.70 MiB/s, done.\n",
            "Resolving deltas: 100% (12085/12085), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "outputId": "bcc36ba7-3e2a-49de-8ebc-6a81ad188231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-10 14:20:25--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.1.0/cloudflared-linux-amd64.deb [following]\n",
            "--2025-01-10 14:20:25--  https://github.com/cloudflare/cloudflared/releases/download/2025.1.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/2d8414e3-a676-4d22-b0ad-71fffb4149a4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250110%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250110T142026Z&X-Amz-Expires=300&X-Amz-Signature=45cf4d0551b54682a2a5ce53f3080a0d5a930708e35ed6491dc887cb983750d9&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-01-10 14:20:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/2d8414e3-a676-4d22-b0ad-71fffb4149a4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250110%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250110T142026Z&X-Amz-Expires=300&X-Amz-Signature=45cf4d0551b54682a2a5ce53f3080a0d5a930708e35ed6491dc887cb983750d9&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18514648 (18M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  17.66M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-01-10 14:20:27 (361 MB/s) - ‘cloudflared-linux-amd64.deb’ saved [18514648/18514648]\n",
            "\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.1.0) ...\n",
            "Setting up cloudflared (2025.1.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "[ComfyUI-Manager] Logging failed: [Errno 2] No such file or directory: '/content/ComfyUI/user/comfyui.log'\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-01-10 14:20:30.309553\n",
            "** Platform: Linux\n",
            "** Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** User directory: /content/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   3.2 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "pytorch version: 2.5.1+cu121\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.5.1+cu118 with CUDA 1108 (you have 2.5.1+cu121)\n",
            "    Python  3.10.16 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "xformers version: 0.0.29.post1\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "****** User settings have been changed to be stored on the server instead of browser storage. ******\n",
            "****** For multi-user setups add the --multi-user CLI argument to enable multiple user profiles. ******\n",
            "[Prompt Server] web root: /content/ComfyUI/web\n",
            "### Loading: ComfyUI-Manager (V3.5.1)\n",
            "### ComfyUI Version: v0.3.10-43-g129d890 | Released on '2025-01-10'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "This is the URL to access ComfyUI: https://greatly-shore-distributor-shed.trycloudflare.com                                  |\n",
            "FETCH DATA from: /content/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
            "Update ComfyUI\n",
            "Install: pip packages\n",
            "\u001b[1m[\u001b[0mComfyUI-Manager\u001b[1m]\u001b[0m skip black listed pip installation: \u001b[32m'torch'\u001b[0m\n",
            "\u001b[1m[\u001b[0mComfyUI-Manager\u001b[1m]\u001b[0m skip black listed pip installation: \u001b[32m'torchsde'\u001b[0m\n",
            "\u001b[1m[\u001b[0mComfyUI-Manager\u001b[1m]\u001b[0m skip black listed pip installation: \u001b[32m'torchvision'\u001b[0m\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'torchaudio'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            " Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\n",
            " Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.16.1)\n",
            " Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            " Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            " Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.5)\n",
            " Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            " Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            " Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            " Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'einops'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'transformers>=4.28.1'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            " Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (3.16.1)\n",
            " Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (0.27.1)\n",
            " Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (1.26.4)\n",
            " Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (24.2)\n",
            " Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (6.0.2)\n",
            " Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (2024.11.6)\n",
            " Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (2.32.3)\n",
            " Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (0.21.0)\n",
            " Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (0.5.0)\n",
            " Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.1) (4.67.1)\n",
            " Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.28.1) (2024.10.0)\n",
            " Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.28.1) (4.12.2)\n",
            " Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1) (3.4.1)\n",
            " Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1) (3.10)\n",
            " Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1) (2.3.0)\n",
            " Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.28.1) (2024.12.14)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'tokenizers>=0.13.3'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            " Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.3) (0.27.1)\n",
            " Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (3.16.1)\n",
            " Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (2024.10.0)\n",
            " Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (24.2)\n",
            " Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (6.0.2)\n",
            " Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (2.32.3)\n",
            " Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (4.67.1)\n",
            " Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (4.12.2)\n",
            " Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (3.4.1)\n",
            " Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (3.10)\n",
            " Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (2.3.0)\n",
            " Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3) (2024.12.14)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'sentencepiece'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'safetensors>=0.4.2'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'aiohttp'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.11.11)\n",
            " Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.4)\n",
            " Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.2)\n",
            " Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            " Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.3.0)\n",
            " Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.5.0)\n",
            " Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            " Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (0.2.1)\n",
            " Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.18.3)\n",
            " Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp) (4.12.2)\n",
            " Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'pyyaml'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'Pillow'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.1.0)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'scipy'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            " Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'tqdm'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'psutil'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Line is comment\u001b[33m...\u001b[0mskipping\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'kornia>=0.7.1'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: kornia>=0.7.1 in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
            " Requirement already satisfied: kornia-rs>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from kornia>=0.7.1) (0.1.8)\n",
            " Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia>=0.7.1) (24.2)\n",
            " Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia>=0.7.1) (2.5.1+cu121)\n",
            " Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia>=0.7.1) (3.16.1)\n",
            " Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia>=0.7.1) (4.12.2)\n",
            " Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia>=0.7.1) (3.4.2)\n",
            " Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia>=0.7.1) (3.1.5)\n",
            " Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia>=0.7.1) (2024.10.0)\n",
            " Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.1->kornia>=0.7.1) (1.13.1)\n",
            " Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.1->kornia>=0.7.1) (1.3.0)\n",
            " Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.1->kornia>=0.7.1) (3.0.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'spandrel'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: spandrel in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            " Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from spandrel) (2.5.1+cu121)\n",
            " Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from spandrel) (0.20.1+cu121)\n",
            " Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from spandrel) (0.5.0)\n",
            " Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spandrel) (1.26.4)\n",
            " Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from spandrel) (0.8.0)\n",
            " Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from spandrel) (4.12.2)\n",
            " Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->spandrel) (3.16.1)\n",
            " Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->spandrel) (3.4.2)\n",
            " Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->spandrel) (3.1.5)\n",
            " Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->spandrel) (2024.10.0)\n",
            " Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->spandrel) (1.13.1)\n",
            " Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->spandrel) (1.3.0)\n",
            " Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->spandrel) (11.1.0)\n",
            " Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->spandrel) (3.0.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \u001b[32m'soundfile'\u001b[0m\u001b[1m]\u001b[0m\n",
            " Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            " Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            " Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.26.4)\n",
            " Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "FETCH DATA from: https://api.comfy.org/nodes?page=1&limit=1000 [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes?page=1&limit=1000\n",
            "nightly_channel: \u001b[4;94mhttps://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\u001b[0m\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extras.json [DONE]\n",
            "Downloading https://storage.googleapis.com/comfy-registry/aemotionstudio/comfyui-christmastheme/1.0.0/node.tar.gz to /content/ComfyUI/custom_nodes/CNR_temp_3c3213e3-81ac-44b7-a72a-509497514af8.zip\n",
            "100% 51.9M/51.9M [00:03<00:00, 15.9MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui-christmastheme\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-01-10 14:26:51.906694\n",
            "** Platform: Linux\n",
            "** Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** User directory: /content/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   2.8 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "pytorch version: 2.5.1+cu121\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.5.1+cu118 with CUDA 1108 (you have 2.5.1+cu121)\n",
            "    Python  3.10.16 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "xformers version: 0.0.29.post1\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "[Prompt Server] web root: /content/ComfyUI/web\n",
            "### Loading: ComfyUI-Manager (V3.5.1)\n",
            "### ComfyUI Version: v0.3.10-44-g2ff3104 | Released on '2025-01-10'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/comfyui-christmastheme\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/2233941102_nodes_page_1_limit_1000.json [DONE]\n",
            "nightly_channel: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            "Downloading https://storage.googleapis.com/comfy-registry/crystian/comfyui-crystools/1.21.0/node.tar.gz to /content/ComfyUI/custom_nodes/CNR_temp_f00d5336-69b7-4ca0-8d69-bdb570b54f69.zip\n",
            "100% 4.98M/4.98M [00:01<00:00, 3.68MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui-crystools\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', 'deepdiff']\n",
            " Collecting deepdiff\n",
            "   Downloading deepdiff-8.1.1-py3-none-any.whl.metadata (9.5 kB)\n",
            " Collecting orderly-set<6,>=5.2.3 (from deepdiff)\n",
            "   Downloading orderly_set-5.2.3-py3-none-any.whl.metadata (6.0 kB)\n",
            " Downloading deepdiff-8.1.1-py3-none-any.whl (84 kB)\n",
            "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.7/84.7 kB 7.3 MB/s eta 0:00:00\n",
            " Downloading orderly_set-5.2.3-py3-none-any.whl (12 kB)\n",
            " Installing collected packages: orderly-set, deepdiff\n",
            " Successfully installed deepdiff-8.1.1 orderly-set-5.2.3\n",
            "[ComfyUI-Manager] skip black listed pip installation: 'torch'\n",
            "[ComfyUI-Manager] 'numpy' is remapped to 'numpy<2'\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', 'numpy<2']\n",
            " \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', 'Pillow>=9.5.0']\n",
            " \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', 'pynvml']\n",
            " Collecting pynvml\n",
            "   Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            " Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml)\n",
            "   Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            " Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            " Downloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 3.7 MB/s eta 0:00:00\n",
            " Installing collected packages: nvidia-ml-py, pynvml\n",
            " Successfully installed nvidia-ml-py-12.560.30 pynvml-12.0.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', 'py-cpuinfo']\n",
            " \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', 'piexif']\n",
            " Collecting piexif\n",
            "   Downloading piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            " Downloading piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            " Installing collected packages: piexif\n",
            " Successfully installed piexif-1.1.3\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-01-10 14:30:51.172838\n",
            "** Platform: Linux\n",
            "** Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** User directory: /content/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   4.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "pytorch version: 2.5.1+cu121\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.5.1+cu118 with CUDA 1108 (you have 2.5.1+cu121)\n",
            "    Python  3.10.16 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "xformers version: 0.0.29.post1\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using pytorch attention\n",
            "[Prompt Server] web root: /content/ComfyUI/web\n",
            "NumExpr defaulting to 2 threads.\n",
            "[Crystools \u001b[0;32mINFO\u001b[0m] Crystools version: 1.21.0\n",
            "[Crystools \u001b[0;32mINFO\u001b[0m] CPU: Intel(R) Xeon(R) CPU @ 2.00GHz - Arch: x86_64 - OS: Linux 6.1.85+\n",
            "[Crystools \u001b[0;32mINFO\u001b[0m] Pynvml (Nvidia) initialized.\n",
            "[Crystools \u001b[0;32mINFO\u001b[0m] GPU/s:\n",
            "[Crystools \u001b[0;32mINFO\u001b[0m] 0) Tesla T4\n",
            "[Crystools \u001b[0;32mINFO\u001b[0m] NVIDIA Driver: 535.104.05\n",
            "### Loading: ComfyUI-Manager (V3.5.1)\n",
            "### ComfyUI Version: v0.3.10-44-g2ff3104 | Released on '2025-01-10'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/comfyui-christmastheme\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   1.2 seconds: /content/ComfyUI/custom_nodes/comfyui-crystools\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "\n",
            "Stopped server\n",
            "Exception ignored in atexit callback: <function dump_compile_times at 0x7d277b8f4af0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 399, in dump_compile_times\n",
            "    log.info(compile_times(repr=\"str\", aggregate=True))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 385, in compile_times\n",
            "    out += tabulate(rows, headers=(\"Function\", \"Runtimes (s)\"))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 148, in tabulate\n",
            "    import tabulate\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1016, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        ":### Run ComfyUI with localtunnel ✈\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPLOAD CHECKPOINT ❤✅😃▶"
      ],
      "metadata": {
        "id": "qPv0NyinXOi0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPLOAD CHECKPOINT(S) ❤✅😃▶"
      ],
      "metadata": {
        "id": "hQ3Hl6Me-Ff9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "model_ids = [12345, 67890, 13579]  # Replace with your model IDs WHICH ARE THE NUMBERS ONLY OF THE CIVIT FILE\n",
        "output_dir = \"/content/ComfyUI/models/checkpoints\"\n",
        "\n",
        "for model_id in model_ids:\n",
        "  download_link = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor\"\n",
        "  !wget -c {download_link} -P {output_dir}"
      ],
      "metadata": {
        "id": "bdlSoD67-EdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename, data in uploaded.items():\n",
        "  with open('/content/ComfyUI/models/checkpoints/' + filename, 'wb') as f:\n",
        "    f.write(data)\n",
        "  print(f'Uploaded: {filename} to /content/ComfyUI/models/checkpoints/')"
      ],
      "metadata": {
        "id": "ENCdvm3Z87id",
        "outputId": "a7072c0c-92ad-4f86-be71-56574d6de526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06bc76a1-8578-4816-b6af-e3c16a347543\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06bc76a1-8578-4816-b6af-e3c16a347543\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-053b7b8ea066>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ComfyUI Cache"
      ],
      "metadata": {
        "id": "mxmWl4ZSK25b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/ComfyUI/temp/*\n"
      ],
      "metadata": {
        "id": "4V-CS_6NK1Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_civitai_model(model_id, output_dir=\"./models/checkpoints\"):\n",
        "    \"\"\"Downloads a model from Civitai.\n",
        "\n",
        "    Args:\n",
        "        model_id: The ID of the model on Civitai.\n",
        "        output_dir: The directory where the model should be saved.\n",
        "    \"\"\"\n",
        "    url = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor&size=full&fp=fp16\"  # Adjust format and fp if needed\n",
        "    filename = os.path.join(output_dir, f\"civitai_model_{model_id}.safetensors\")\n",
        "\n",
        "    print(f\"Downloading from URL: {url}\")  # Print the download URL for debugging\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        print(f\"Response status code: {response.status_code}\")  # Print status code\n",
        "\n",
        "        if response.status_code == 200:  # Check if the request was successful\n",
        "            with open(filename, \"wb\") as f:\n",
        "                total_length = response.headers.get('content-length')\n",
        "                if total_length is None:  # no content length header\n",
        "                    f.write(response.content)\n",
        "                else:\n",
        "                    dl = 0\n",
        "                    total_length = int(total_length)\n",
        "                    for data in response.iter_content(chunk_size=4096):\n",
        "                        dl += len(data)\n",
        "                        f.write(data)\n",
        "                        done = int(50 * dl / total_length)\n",
        "                        print(f\"\\r[{done * '=' + (50-done) * ' '}] {done * 2}%\", end='', flush=True)\n",
        "                    print(\"\")  # Newline after progress bar\n",
        "            print(f\"Model {model_id} downloaded to {filename}\")\n",
        "        else:\n",
        "            print(f\"Error downloading model {model_id}. Status code: {response.status_code}\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"Request Exception: {err}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_ids = [552771]  # Your desired model ID\n",
        "    os.makedirs(\"./models/checkpoints\", exist_ok=True)  # Create output directory if it doesn't exist\n",
        "    for model_id in model_ids:\n",
        "        download_civitai_model(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQHnrFXVFxi8",
        "outputId": "d6167dcb-71ba-4e32-f34b-cc98e463088c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from URL: https://civitai.com/api/download/models/552771?type=Model&format=SafeTensor&size=full&fp=fp16\n",
            "Response status code: 401\n",
            "Error downloading model 552771. Status code: 401\n"
          ]
        }
      ]
    },
    {
      "source": [
        "pip install requests"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iPiicYx6PDd",
        "outputId": "39fdd794-00d8-4032-d7fe-b36018ada338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downlad and create a specific folder"
      ],
      "metadata": {
        "id": "uPDrGaGU0xhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./models/checkpoints/sd1.5 #I CAN CHANGE THE SCRIPT TO lora/MY LORA,AS LONG AS I FOLLOW THE CORRECT STRUCTURE, WITH THE (/) IN BETWEEN FOLDERS\n",
        "!wget -c https://civitai.com/api/download/models/552771?type=Model&format=SafeTensor&size=full&fp=fp16 -O \"./models/checkpoints/sd1.5\" #the first part is the actual link, which needs to be copied #the second part indicates the folder where the model will be downloaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRg2G63T0dxx",
        "outputId": "af09873c-5867-4dee-c6c6-6c9364e44e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: -O: command not found\n",
            "--2024-12-15 19:54:15--  https://civitai.com/api/download/models/552771?type=Model\n",
            "Resolving civitai.com (civitai.com)... 104.22.18.237, 104.22.19.237, 172.67.12.143, ...\n",
            "Connecting to civitai.com (civitai.com)|104.22.18.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint-LoRA etc examples to download Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ],
      "metadata": {
        "id": "A44se_RS1DN0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d673201b-0d56-4d82-9ed3-5d8c1f69e2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-17 19:25:25--  https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.118, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/7f/2f/7f2fe2e27137549cd28e570e5bac269b49ebcf1e0e47279c7a941ebe5c948e02/31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sd_xl_base_1.0.safetensors%3B+filename%3D%22sd_xl_base_1.0.safetensors%22%3B&Expires=1734722087&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjA4N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83Zi8yZi83ZjJmZTJlMjcxMzc1NDljZDI4ZTU3MGU1YmFjMjY5YjQ5ZWJjZjFlMGU0NzI3OWM3YTk0MWViZTVjOTQ4ZTAyLzMxZTM1YzgwZmM0ODI5ZDE0ZjkwMTUzZjRjNzRjZDU5YzkwYjc3OWY2YWZlMDVhNzRjZDYxMjBiODkzZjdlNWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=nglWSbrWoTrT9dAmLJtmcPJgyQZRu6rXAUvp-dHNG7D3bHyM%7EtKBCs0FhQlS-grqk%7EjFICgaQ1EyeppkPmx1e%7EKE%7EPaPCZh0gjr1BcaY9GkyYD63W11xcdUWjhfvSH7lZccmhoSoM8EQW%7EQa2B-SmRPXYVm%7EoDrZ-yBYUJKov3nzRZoejeOwk5KDfEJ0e%7EygzADX8r8yaHDjFPQ6WkaI7s4HLhCRsu2pWuc%7ELqhwECmx34naIB0Gn3KbiCSWYzXuR8fFRUphAbug9GY6KvgjpvFj%7EUzB4V8Wk0PJGsm7ajYsoDAfFgUGh5F4yAlpFZdKIDnh5mnosoNwwL3qP5cLDw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-17 19:25:26--  https://cdn-lfs.hf.co/repos/7f/2f/7f2fe2e27137549cd28e570e5bac269b49ebcf1e0e47279c7a941ebe5c948e02/31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sd_xl_base_1.0.safetensors%3B+filename%3D%22sd_xl_base_1.0.safetensors%22%3B&Expires=1734722087&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjA4N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy83Zi8yZi83ZjJmZTJlMjcxMzc1NDljZDI4ZTU3MGU1YmFjMjY5YjQ5ZWJjZjFlMGU0NzI3OWM3YTk0MWViZTVjOTQ4ZTAyLzMxZTM1YzgwZmM0ODI5ZDE0ZjkwMTUzZjRjNzRjZDU5YzkwYjc3OWY2YWZlMDVhNzRjZDYxMjBiODkzZjdlNWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=nglWSbrWoTrT9dAmLJtmcPJgyQZRu6rXAUvp-dHNG7D3bHyM%7EtKBCs0FhQlS-grqk%7EjFICgaQ1EyeppkPmx1e%7EKE%7EPaPCZh0gjr1BcaY9GkyYD63W11xcdUWjhfvSH7lZccmhoSoM8EQW%7EQa2B-SmRPXYVm%7EoDrZ-yBYUJKov3nzRZoejeOwk5KDfEJ0e%7EygzADX8r8yaHDjFPQ6WkaI7s4HLhCRsu2pWuc%7ELqhwECmx34naIB0Gn3KbiCSWYzXuR8fFRUphAbug9GY6KvgjpvFj%7EUzB4V8Wk0PJGsm7ajYsoDAfFgUGh5F4yAlpFZdKIDnh5mnosoNwwL3qP5cLDw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.51, 3.168.132.99, 3.168.132.48, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6938078334 (6.5G) [binary/octet-stream]\n",
            "Saving to: ‘./models/checkpoints/sd_xl_base_1.0.safetensors’\n",
            "\n",
            "sd_xl_base_1.0.safe 100%[===================>]   6.46G  57.5MB/s    in 52s     \n",
            "\n",
            "2024-12-17 19:26:18 (127 MB/s) - ‘./models/checkpoints/sd_xl_base_1.0.safetensors’ saved [6938078334/6938078334]\n",
            "\n",
            "--2024-12-17 19:26:18--  https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.118, 18.164.174.23, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/ce/d3/ced31dbff26495591d2414c72203e0628a90376396736d14acab944c51f70305/7440042bbdc8a24813002c09b6b69b64dc90fded4472613437b7f55f9b7d9c5f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sd_xl_refiner_1.0.safetensors%3B+filename%3D%22sd_xl_refiner_1.0.safetensors%22%3B&Expires=1734722778&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjc3OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jZS9kMy9jZWQzMWRiZmYyNjQ5NTU5MWQyNDE0YzcyMjAzZTA2MjhhOTAzNzYzOTY3MzZkMTRhY2FiOTQ0YzUxZjcwMzA1Lzc0NDAwNDJiYmRjOGEyNDgxMzAwMmMwOWI2YjY5YjY0ZGM5MGZkZWQ0NDcyNjEzNDM3YjdmNTVmOWI3ZDljNWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=pt4x01RXQ6Wubk9yLe-WVEPVIOo4KLhFbckP0tE4GrpFAfjB4NQZqoNt0JMgAPm4nMchWwsRZ6uiNe%7E2EVvkZSh1iD8T7QuQTFXf9BHdvCx8wEcXqvKfkXc0zc2exCQxHzhm5DRdFUNsz9MyphhsyAKq4j22DTy2LxWxE%7EiFbuG%7ERD9rxISF6VS-Ql1o0Ce8rOazVXgZ0RN8WGcyvlz4AQUubs62GCOEaEzV9hdWBa2-xR6jdHEM0c5-dDxKMIeKelJtIqKLTY3F6DY-DibRDWRb9F3xc9T-WQVSiPV7NqRELItQuoRyvP6K7FH8YCTHtYLG%7EIywOz0177190U3aJg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-17 19:26:18--  https://cdn-lfs.hf.co/repos/ce/d3/ced31dbff26495591d2414c72203e0628a90376396736d14acab944c51f70305/7440042bbdc8a24813002c09b6b69b64dc90fded4472613437b7f55f9b7d9c5f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27sd_xl_refiner_1.0.safetensors%3B+filename%3D%22sd_xl_refiner_1.0.safetensors%22%3B&Expires=1734722778&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjc3OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jZS9kMy9jZWQzMWRiZmYyNjQ5NTU5MWQyNDE0YzcyMjAzZTA2MjhhOTAzNzYzOTY3MzZkMTRhY2FiOTQ0YzUxZjcwMzA1Lzc0NDAwNDJiYmRjOGEyNDgxMzAwMmMwOWI2YjY5YjY0ZGM5MGZkZWQ0NDcyNjEzNDM3YjdmNTVmOWI3ZDljNWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=pt4x01RXQ6Wubk9yLe-WVEPVIOo4KLhFbckP0tE4GrpFAfjB4NQZqoNt0JMgAPm4nMchWwsRZ6uiNe%7E2EVvkZSh1iD8T7QuQTFXf9BHdvCx8wEcXqvKfkXc0zc2exCQxHzhm5DRdFUNsz9MyphhsyAKq4j22DTy2LxWxE%7EiFbuG%7ERD9rxISF6VS-Ql1o0Ce8rOazVXgZ0RN8WGcyvlz4AQUubs62GCOEaEzV9hdWBa2-xR6jdHEM0c5-dDxKMIeKelJtIqKLTY3F6DY-DibRDWRb9F3xc9T-WQVSiPV7NqRELItQuoRyvP6K7FH8YCTHtYLG%7EIywOz0177190U3aJg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.48, 3.168.132.25, 3.168.132.51, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6075981930 (5.7G) [binary/octet-stream]\n",
            "Saving to: ‘./models/checkpoints/sd_xl_refiner_1.0.safetensors’\n",
            "\n",
            "sd_xl_refiner_1.0.s 100%[===================>]   5.66G  67.2MB/s    in 40s     \n",
            "\n",
            "2024-12-17 19:26:58 (146 MB/s) - ‘./models/checkpoints/sd_xl_refiner_1.0.safetensors’ saved [6075981930/6075981930]\n",
            "\n",
            "/bin/bash: line 1: -P: command not found\n",
            "--2024-12-17 19:26:58--  https://civitai.com/api/download/models/552771?type=Model\n",
            "Resolving civitai.com (civitai.com)... 104.22.18.237, 104.22.19.237, 172.67.12.143, ...\n",
            "Connecting to civitai.com (civitai.com)|104.22.18.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n",
            "--2024-12-17 19:26:58--  https://civitai.com/models/978314/ultrareal-fine-tune\n",
            "Resolving civitai.com (civitai.com)... 104.22.18.237, 104.22.19.237, 172.67.12.143, ...\n",
            "Connecting to civitai.com (civitai.com)|104.22.18.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./models/checkpoints/ultrareal-fine-tune’\n",
            "\n",
            "ultrareal-fine-tune     [ <=>                ] 250.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-12-17 19:26:59 (12.6 MB/s) - ‘./models/checkpoints/ultrareal-fine-tune’ saved [256315]\n",
            "\n",
            "--2024-12-17 19:27:00--  https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.118, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1734721995&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMTk5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=VrXGSsyBlAfA6n0NCf-5qWHrBzIU4J3qutFUCD3LnI9layLcc9soMe3RCjZNBxm-ZG3klQDQ2lfC96ZClOmrmRjan%7EDrO7oWs9gur7fBHvvLUOxh5x5TO3H-jhqk9Mow-rXxOGnFD%7Ei0szC-bsICbMQvMzZQ7DKgB21YeYbftGeyKx-w4QHQzjh3d4kw3OJMba7IXCK%7Eau%7EmwdgPyv6U1RglaTnP7FmBBfvc60EdK4URkfCW1Vr62xwnf2X0DrC738fIawKOspSa1WetX3PMSXekUZWXuKduS5njXqhzVBgZeA9eI%7EQAvllQQpDlgKLBD7v3WDBg3da59v4NFnJEmw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-17 19:27:00--  https://cdn-lfs.hf.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1734721995&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMTk5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=VrXGSsyBlAfA6n0NCf-5qWHrBzIU4J3qutFUCD3LnI9layLcc9soMe3RCjZNBxm-ZG3klQDQ2lfC96ZClOmrmRjan%7EDrO7oWs9gur7fBHvvLUOxh5x5TO3H-jhqk9Mow-rXxOGnFD%7Ei0szC-bsICbMQvMzZQ7DKgB21YeYbftGeyKx-w4QHQzjh3d4kw3OJMba7IXCK%7Eau%7EmwdgPyv6U1RglaTnP7FmBBfvc60EdK4URkfCW1Vr62xwnf2X0DrC738fIawKOspSa1WetX3PMSXekUZWXuKduS5njXqhzVBgZeA9eI%7EQAvllQQpDlgKLBD7v3WDBg3da59v4NFnJEmw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.48, 3.168.132.99, 3.168.132.51, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 334641190 (319M) [binary/octet-stream]\n",
            "Saving to: ‘./models/vae/vae-ft-mse-840000-ema-pruned.safetensors’\n",
            "\n",
            "vae-ft-mse-840000-e 100%[===================>] 319.14M   213MB/s    in 1.5s    \n",
            "\n",
            "2024-12-17 19:27:01 (213 MB/s) - ‘./models/vae/vae-ft-mse-840000-ema-pruned.safetensors’ saved [334641190/334641190]\n",
            "\n",
            "--2024-12-17 19:27:01--  https://civitai.com/models/968352/exhibition-booth-flux1-d\n",
            "Resolving civitai.com (civitai.com)... 104.22.18.237, 104.22.19.237, 172.67.12.143, ...\n",
            "Connecting to civitai.com (civitai.com)|104.22.18.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./models/loras/exhibition-booth-flux1-d’\n",
            "\n",
            "exhibition-booth-fl     [ <=>                ] 223.69K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-17 19:27:02 (8.08 MB/s) - ‘./models/loras/exhibition-booth-flux1-d’ saved [229058]\n",
            "\n",
            "--2024-12-17 19:27:02--  https://civitai.com/models/956649/exhibition-booth-sd\n",
            "Resolving civitai.com (civitai.com)... 104.22.18.237, 104.22.19.237, 172.67.12.143, ...\n",
            "Connecting to civitai.com (civitai.com)|104.22.18.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./models/loras/exhibition-booth-sd’\n",
            "\n",
            "exhibition-booth-sd     [ <=>                ] 219.99K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-17 19:27:02 (7.54 MB/s) - ‘./models/loras/exhibition-booth-sd’ saved [225272]\n",
            "\n",
            "--2024-12-17 19:27:02--  https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.118, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/06/f2/06f2715698cc0f2fce8aa59e17548ba6e86afda736cc5eb3c908cd396b5fc580/8932b66e15aae835b3490dbf989f56c253104cee08a88bf21283762f557c9f10?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27control_v11p_sd15_canny_fp16.safetensors%3B+filename%3D%22control_v11p_sd15_canny_fp16.safetensors%22%3B&Expires=1734721207&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMTIwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wNi9mMi8wNmYyNzE1Njk4Y2MwZjJmY2U4YWE1OWUxNzU0OGJhNmU4NmFmZGE3MzZjYzVlYjNjOTA4Y2QzOTZiNWZjNTgwLzg5MzJiNjZlMTVhYWU4MzViMzQ5MGRiZjk4OWY1NmMyNTMxMDRjZWUwOGE4OGJmMjEyODM3NjJmNTU3YzlmMTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=T%7E9cPwlfnzmNHbxVxBpnnvz8ePoBsWxOMhqSpBaMBCZeVqnQpVCpsz8YzdHBDWyS0qW3NMwnOhhnMyty%7ENNeK5AJio1cE%7E-0e96gqkbklK1-XvSXwupb93%7E6sbhZjOjyDMwx1dGYYvV9W-3R4K-Ik25wXVkIa-KLqPp9F0DmU%7Ec4HuIelAfLpN0fD4OsPKByhNzXWgEL3MDlQobe2dg1YNEZhjX5ynzTizirM8IjWJi75XfGB1dD5QRbzAKMTNjS%7EHa6peIyft4rg8GFSnVNskNTPG-HwDsnvrOvTWjmWHkULIvWgLqzWQG3vhQZXbyHv4VqSFK2P2lpBwA-3joj6w__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-17 19:27:02--  https://cdn-lfs.hf.co/repos/06/f2/06f2715698cc0f2fce8aa59e17548ba6e86afda736cc5eb3c908cd396b5fc580/8932b66e15aae835b3490dbf989f56c253104cee08a88bf21283762f557c9f10?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27control_v11p_sd15_canny_fp16.safetensors%3B+filename%3D%22control_v11p_sd15_canny_fp16.safetensors%22%3B&Expires=1734721207&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMTIwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wNi9mMi8wNmYyNzE1Njk4Y2MwZjJmY2U4YWE1OWUxNzU0OGJhNmU4NmFmZGE3MzZjYzVlYjNjOTA4Y2QzOTZiNWZjNTgwLzg5MzJiNjZlMTVhYWU4MzViMzQ5MGRiZjk4OWY1NmMyNTMxMDRjZWUwOGE4OGJmMjEyODM3NjJmNTU3YzlmMTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=T%7E9cPwlfnzmNHbxVxBpnnvz8ePoBsWxOMhqSpBaMBCZeVqnQpVCpsz8YzdHBDWyS0qW3NMwnOhhnMyty%7ENNeK5AJio1cE%7E-0e96gqkbklK1-XvSXwupb93%7E6sbhZjOjyDMwx1dGYYvV9W-3R4K-Ik25wXVkIa-KLqPp9F0DmU%7Ec4HuIelAfLpN0fD4OsPKByhNzXWgEL3MDlQobe2dg1YNEZhjX5ynzTizirM8IjWJi75XfGB1dD5QRbzAKMTNjS%7EHa6peIyft4rg8GFSnVNskNTPG-HwDsnvrOvTWjmWHkULIvWgLqzWQG3vhQZXbyHv4VqSFK2P2lpBwA-3joj6w__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.51, 3.168.132.48, 3.168.132.25, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 722601100 (689M) [binary/octet-stream]\n",
            "Saving to: ‘./models/controlnet/control_v11p_sd15_canny_fp16.safetensors’\n",
            "\n",
            "control_v11p_sd15_c 100%[===================>] 689.13M   122MB/s    in 5.6s    \n",
            "\n",
            "2024-12-17 19:27:08 (122 MB/s) - ‘./models/controlnet/control_v11p_sd15_canny_fp16.safetensors’ saved [722601100/722601100]\n",
            "\n",
            "--2024-12-17 19:27:08--  https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/06/f2/06f2715698cc0f2fce8aa59e17548ba6e86afda736cc5eb3c908cd396b5fc580/677a4fe351edecd40cd0d7cc210a8686b59d4e55207317f12319ef746a7a5a89?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27control_v11p_sd15_inpaint_fp16.safetensors%3B+filename%3D%22control_v11p_sd15_inpaint_fp16.safetensors%22%3B&Expires=1734722828&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjgyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wNi9mMi8wNmYyNzE1Njk4Y2MwZjJmY2U4YWE1OWUxNzU0OGJhNmU4NmFmZGE3MzZjYzVlYjNjOTA4Y2QzOTZiNWZjNTgwLzY3N2E0ZmUzNTFlZGVjZDQwY2QwZDdjYzIxMGE4Njg2YjU5ZDRlNTUyMDczMTdmMTIzMTllZjc0NmE3YTVhODk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=h2gsD%7EhMIlqAvrC4ghSXKTh8zAploneB379cs2NIsgCyx5p82QYJzob4WWyfylEsbA7dXVSiyWVxqnl1Yj6Q4uiXbKFSlXNiEPf-Dc2C686NlXZHZ0epEgKlPtzPz4EmInnvZ2aeb4kUxod8PLuL8KqxzqMIWZvMENxNWqaiK5G642UWjowH-Ay4UJAAGnaByyW7fYMHP8jZ0Q6x6Y6KcZfsQLRZ9zoqjitabj3Uem5yW61iQjJ7Prt0ediXizxhpNOF3-2kIdxR6cPJIavD5P8CZfUXq60fUtR9rCC6uE6qcZhn61lULr7srXhn2pCfYsTWLLaZJgeD%7E9qYoEVTkg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-17 19:27:08--  https://cdn-lfs.hf.co/repos/06/f2/06f2715698cc0f2fce8aa59e17548ba6e86afda736cc5eb3c908cd396b5fc580/677a4fe351edecd40cd0d7cc210a8686b59d4e55207317f12319ef746a7a5a89?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27control_v11p_sd15_inpaint_fp16.safetensors%3B+filename%3D%22control_v11p_sd15_inpaint_fp16.safetensors%22%3B&Expires=1734722828&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjgyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wNi9mMi8wNmYyNzE1Njk4Y2MwZjJmY2U4YWE1OWUxNzU0OGJhNmU4NmFmZGE3MzZjYzVlYjNjOTA4Y2QzOTZiNWZjNTgwLzY3N2E0ZmUzNTFlZGVjZDQwY2QwZDdjYzIxMGE4Njg2YjU5ZDRlNTUyMDczMTdmMTIzMTllZjc0NmE3YTVhODk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=h2gsD%7EhMIlqAvrC4ghSXKTh8zAploneB379cs2NIsgCyx5p82QYJzob4WWyfylEsbA7dXVSiyWVxqnl1Yj6Q4uiXbKFSlXNiEPf-Dc2C686NlXZHZ0epEgKlPtzPz4EmInnvZ2aeb4kUxod8PLuL8KqxzqMIWZvMENxNWqaiK5G642UWjowH-Ay4UJAAGnaByyW7fYMHP8jZ0Q6x6Y6KcZfsQLRZ9zoqjitabj3Uem5yW61iQjJ7Prt0ediXizxhpNOF3-2kIdxR6cPJIavD5P8CZfUXq60fUtR9rCC6uE6qcZhn61lULr7srXhn2pCfYsTWLLaZJgeD%7E9qYoEVTkg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.51, 3.168.132.48, 3.168.132.25, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 722601100 (689M) [binary/octet-stream]\n",
            "Saving to: ‘./models/controlnet/control_v11p_sd15_inpaint_fp16.safetensors’\n",
            "\n",
            "control_v11p_sd15_i 100%[===================>] 689.13M  60.4MB/s    in 8.7s    \n",
            "\n",
            "2024-12-17 19:27:17 (78.9 MB/s) - ‘./models/controlnet/control_v11p_sd15_inpaint_fp16.safetensors’ saved [722601100/722601100]\n",
            "\n",
            "--2024-12-17 19:27:17--  https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/2f/38/2f383af98def7e9ee8b44a8642a849c43d9615d948564c1dd1871edd7bec0cdf/21f79f7368eff07f57bcd507ca91c0fc89070d7da182960ff24ed1d58310c3a7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27control-lora-canny-rank256.safetensors%3B+filename%3D%22control-lora-canny-rank256.safetensors%22%3B&Expires=1734722837&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjgzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZi8zOC8yZjM4M2FmOThkZWY3ZTllZThiNDRhODY0MmE4NDljNDNkOTYxNWQ5NDg1NjRjMWRkMTg3MWVkZDdiZWMwY2RmLzIxZjc5ZjczNjhlZmYwN2Y1N2JjZDUwN2NhOTFjMGZjODkwNzBkN2RhMTgyOTYwZmYyNGVkMWQ1ODMxMGMzYTc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=fN-L6LYdP5n5MVOnzaBOTSgPfR6YsBA6GREjApuPcEXwtoBnFPcih3qS2AnuPxvreaU6MvTsdRvPAyFmxxAW3L87sZP09eJ8Bsu8uledtNCQShJ29GXgOX4QEGDBDoCtFu5DUhci%7Ea6hqlfLyeav8JrXp3GAc7MUpIU2ZLz34xNIHFrFqnCqcBWCa4fdA6hgGQkhkJP3C7M8MFCP6GVJx1iUGM6Om22oLAqiTK7xf5MAXMiN5Age7894aXz9D7W-mRNlfXCEOWVx85WnW4V-dmwFFgIK4L9Qsg3Kxlk5xjS84lj2UrC-Dn9eaHtu1v%7EhuLB8negdGP7OZRblYB9Oqw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-12-17 19:27:17--  https://cdn-lfs.hf.co/repos/2f/38/2f383af98def7e9ee8b44a8642a849c43d9615d948564c1dd1871edd7bec0cdf/21f79f7368eff07f57bcd507ca91c0fc89070d7da182960ff24ed1d58310c3a7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27control-lora-canny-rank256.safetensors%3B+filename%3D%22control-lora-canny-rank256.safetensors%22%3B&Expires=1734722837&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDcyMjgzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZi8zOC8yZjM4M2FmOThkZWY3ZTllZThiNDRhODY0MmE4NDljNDNkOTYxNWQ5NDg1NjRjMWRkMTg3MWVkZDdiZWMwY2RmLzIxZjc5ZjczNjhlZmYwN2Y1N2JjZDUwN2NhOTFjMGZjODkwNzBkN2RhMTgyOTYwZmYyNGVkMWQ1ODMxMGMzYTc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=fN-L6LYdP5n5MVOnzaBOTSgPfR6YsBA6GREjApuPcEXwtoBnFPcih3qS2AnuPxvreaU6MvTsdRvPAyFmxxAW3L87sZP09eJ8Bsu8uledtNCQShJ29GXgOX4QEGDBDoCtFu5DUhci%7Ea6hqlfLyeav8JrXp3GAc7MUpIU2ZLz34xNIHFrFqnCqcBWCa4fdA6hgGQkhkJP3C7M8MFCP6GVJx1iUGM6Om22oLAqiTK7xf5MAXMiN5Age7894aXz9D7W-mRNlfXCEOWVx85WnW4V-dmwFFgIK4L9Qsg3Kxlk5xjS84lj2UrC-Dn9eaHtu1v%7EhuLB8negdGP7OZRblYB9Oqw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.99, 3.168.132.25, 3.168.132.51, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 774450192 (739M) [binary/octet-stream]\n",
            "Saving to: ‘./models/controlnet/control-lora-canny-rank256.safetensors’\n",
            "\n",
            "control-lora-canny- 100%[===================>] 738.57M   158MB/s    in 5.2s    \n",
            "\n",
            "2024-12-17 19:27:23 (143 MB/s) - ‘./models/controlnet/control-lora-canny-rank256.safetensors’ saved [774450192/774450192]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checkpoints\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD3\n",
        "!wget -c https://civitai.com/api/download/models/552771?type=Model&format=SafeTensor&size=full&fp=fp16 -P ./models/checkpoints/\n",
        "\n",
        "# SD1.5\n",
        "#wget -c https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/resolve/main/v1-5-pruned-emaonly-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Flux\n",
        "!wget -c https://civitai.com/models/978314/ultrareal-fine-tune -P ./models/checkpoints\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "!wget -c https://civitai.com/models/968352/exhibition-booth-flux1-d -P ./models/loras #My Lora Exhibition Booth - Flux.1 D\n",
        "!wget -c https://civitai.com/models/956649/exhibition-booth-sd -P ./models/loras #My Lora Exhibition Booth - SD\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}